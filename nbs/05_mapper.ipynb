{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f4bcfd",
   "metadata": {},
   "source": [
    "# Mapper\n",
    "\n",
    "> Maps IOM evaluation report against evaluation frameworks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbef3dd",
   "metadata": {},
   "source": [
    "Maps evaluation reports to IOM's SRF(Strategic Results Framework) and GCM (Global Compact for Migration UN General Assembly resolution) themes using LLM-based scoring. The module analyzes reports against four theme hierarchies (SRF Enablers, Cross-cutting Priorities, GCM Objectives, and SRF Outputs) using prompt caching for efficiency. Returns structured centrality scores with reasoning and confidence levels for each theme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a58a80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.all import *\n",
    "from pydantic import BaseModel\n",
    "from lisette.core import completion, mk_msg\n",
    "from iomeval.core import load_prompt, n_tokens\n",
    "from iomeval.themes import load_enablers, load_ccp, load_gcms, load_srf_outs, load_gcm_lut, fmt_enablers_ccp, fmt_srf_outs, get_srf_outs, load_all_themes\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc06308",
   "metadata": {},
   "source": [
    "## Response Models\n",
    "\n",
    "`ThemeScore` and `ThemeScores` are Pydantic models for structured LLM output. The LLM returns scores for each theme with reasoning and confidence levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ThemeScore(BaseModel):\n",
    "    \"Single theme's centrality assessment with score, reasoning, and confidence\"\n",
    "    theme_id: str       # Unique identifier for the theme\n",
    "    theme_title: str    # Human-readable theme name\n",
    "    centrality_score: float  # 0-1 score indicating how central theme is to report\n",
    "    reasoning: str      # LLM's explanation for the score\n",
    "    confidence: str     # high/medium/low confidence in assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ThemeScores(BaseModel):\n",
    "    \"Collection of theme centrality scores from a single mapping operation\"\n",
    "    scores: list[ThemeScore]  # All theme scores for a single mapping call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a72f53",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Helper functions to extract and sort results from the LLM response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_json_response(res): \n",
    "    \"Extract and parse JSON content from LLM completion response\"\n",
    "    return json.loads(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69bb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort_by_centrality(res):\n",
    "    \"Sort themes by centrality score, accepts raw response or parsed dict\"\n",
    "    data = res if isinstance(res, dict) else parse_json_response(res)\n",
    "    return sorted(data['scores'], key=lambda x: x['centrality_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_top_ids(res, min_score=0.7):\n",
    "    \"Get IDs of themes with centrality score >= min_score, accepts raw response or parsed dict\"\n",
    "    data = res if isinstance(res, dict) else parse_json_response(res)\n",
    "    return [o['theme_id'] for o in data['scores'] if o['centrality_score'] >= min_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94400d03",
   "metadata": {},
   "source": [
    "## Core Mapping\n",
    "\n",
    "The core mapping functions prepare the report for caching and call the LLM to score themes against the report content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_system_blocks(report:str  # Full report text to analyze\n",
    "                    ) -> list:   # Anthropic-style content blocks with cache control\n",
    "    \"Create cached system message blocks from report text\"\n",
    "    return [{\"type\": \"text\", \"text\": f\"## Report to Analyze\\n\\n{report}\", \"cache_control\": {\"type\": \"ephemeral\"}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76603e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def map_themes(system_blocks:list,   # Cached system blocks from mk_system_blocks\n",
    "               themes:str,            # Formatted themes text to score against\n",
    "               prompt:str,            # Mapping instruction prompt\n",
    "               model:str='claude-haiku-4-5',  # Model to use for completion\n",
    "               response_format=ThemeScores    # Pydantic model for structured output\n",
    "              ):\n",
    "    \"Map report against themes using cached system blocks\"\n",
    "    return completion(model=model, system=system_blocks, messages=[mk_msg(f\"{prompt}\\n\\n## Themes\\n\\n{themes}\")], \n",
    "                     response_format=response_format, max_tokens=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from iomeval.extract import extract_sections\n",
    "from mistocr.core import read_pgs\n",
    "\n",
    "md = read_pgs('files/test/AAP%20Evaluation%20Report_final_')\n",
    "report = extract_sections(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a5d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8657"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "n_tokens(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da168153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Report to Analyze\n",
      "\n",
      "## EXECUTIVE SUMMARY  ... page 6\n",
      "\n",
      "This external evaluation assessed whether or not IOM is delivering on its commitments to accountability to affected populations (AAP), ${ }^{1}$\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "system_blocks = mk_system_blocks(report)\n",
    "print(system_blocks[0]['text'][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a4f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'theme_id': 'Cross-cutting 3',\n",
       "  'theme_title': 'Funding',\n",
       "  'centrality_score': 0.81,\n",
       "  'reasoning': \"Funding is a MAJOR COMPONENT throughout the evaluation. Executive Summary states 'Resources allocated to central AAP functions remain inadequate' and notes 'AAP Coordination Unit is largely funded with earmarked funds.' Conclusions emphasize inadequate resource allocation repeatedly: 'The opinion that resources allocated to AAP in IOM are inadequate was prevalent in both qualitative and quantitative data.' Recommendations 2, 4, and 5 directly address funding strategy and mechanisms (e.g., 'three-year plan connected to a funding strategy'; 'Establish a fund for supporting select country offices'). The Ethiopia case study exemplifies office-wide funding approach. Multiple findings address unsustainability risks from fragmented, project-specific funding models.\",\n",
       "  'confidence': 'high'},\n",
       " {'theme_id': 'Cross-cutting 4',\n",
       "  'theme_title': 'Data and evidence',\n",
       "  'centrality_score': 0.75,\n",
       "  'reasoning': \"Data and evidence is a MAJOR COMPONENT, particularly regarding CFMs and feedback utilization. The evaluation identifies gaps: 'lack of technical resources and support to make full use of data gathered from affected people' (Executive Summary); Conclusions note 'need to structure or strengthen the processes that translate feedback into meaningful operational adjustments' and 'some informants perceived that not all data gathered from affected people were being used.' Recommendation 8 extensively addresses CFM system mapping, data standardization, and analysis ('CFM data analysis dashboards'). However, the evaluation does not address IOM's broader data for foresight, anticipatory action, or data as central to organizational decision-making.\",\n",
       "  'confidence': 'high'},\n",
       " {'theme_id': 'Cross-cutting 5',\n",
       "  'theme_title': 'Learning and Innovation',\n",
       "  'centrality_score': 0.68,\n",
       "  'reasoning': \"Learning and innovation is a SIGNIFICANT/MAJOR element. Executive Summary identifies demand for 'learning and to proactively support IOM country offices.' Recommendation 7 addresses 'training opportunities and update capacity-building material with increased focus on practical AAP implementation,' with emphasis on knowledge sharing through 'communities of practice.' Recommendation 6 focuses on visibility and knowledge management for AAP good practices. Case studies document 'innovative' AAP approaches (e.g., IOM TÃ¼rkiye's cross-border operations). However, the evaluation does not systematically address innovation as organizational capability, technology use, private sector collaboration, or learning as internal decision-making processes beyond AAP domain.\",\n",
       "  'confidence': 'high'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "enablers = load_enablers()\n",
    "prompt = load_prompt('srf_enablers')\n",
    "res = map_themes(system_blocks, fmt_enablers_ccp(enablers), prompt)\n",
    "sort_by_centrality(res)[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76b17c",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "The full pipeline maps a report against all theme hierarchies: SRF Enablers â†’ Cross-cutting Priorities â†’ GCM Objectives â†’ SRF Outputs. The GCM lookup table filters which outputs to score based on top GCM objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_prompts(path:str='files/prompts'  # Directory containing prompt files\n",
    "                ) -> AttrDict:              # Dict with srf_enablers, srf_ccps, gcm, srf_outputs prompts\n",
    "    \"Load all mapping prompts\"\n",
    "    return AttrDict({k: load_prompt(k, path) for k in ['srf_enablers', 'srf_ccps', 'gcm', 'srf_outputs']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c29cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(map_themes)\n",
    "def map_all(report:str,                      # Full report text to analyze\n",
    "            path:str='files/themes',         # Directory containing theme JSON files\n",
    "            prompt_path:str='files/prompts', # Directory containing prompt files\n",
    "            verbose:bool=True,               # Print progress messages\n",
    "            **kwargs                         # Additional args passed to map_themes (e.g. model)\n",
    "           ) -> AttrDict:                    # Dict with enablers, ccp, gcm, outputs results\n",
    "    \"Map report against all theme classes: enablers â†’ CCP â†’ GCM â†’ outputs\"\n",
    "    themes, prompts = load_all_themes(path), load_prompts(prompt_path)\n",
    "    system_blocks = mk_system_blocks(report)\n",
    "    \n",
    "    if verbose: print(\"Mapping SRF Enablers...\")\n",
    "    enablers_res = map_themes(system_blocks, fmt_enablers_ccp(themes.enablers), prompts.srf_enablers, **kwargs)\n",
    "    if verbose: print(\"Mapping Cross-cutting Priorities...\")\n",
    "    ccp_res = map_themes(system_blocks, fmt_enablers_ccp(themes.ccp), prompts.srf_ccps, **kwargs)\n",
    "    if verbose: print(\"Mapping GCM Objectives...\")\n",
    "    gcm_res = map_themes(system_blocks, themes.gcms, prompts.gcm, **kwargs)\n",
    "    \n",
    "    top_gcm_ids = get_top_ids(gcm_res)\n",
    "    if not top_gcm_ids:\n",
    "        if verbose: print(\"No GCM objectives scored â‰¥0.7, skipping SRF Outputs\")\n",
    "        return AttrDict(enablers=enablers_res, ccp=ccp_res, gcm=gcm_res, outputs=None)\n",
    "    \n",
    "    if verbose: print(f\"Top GCM: {top_gcm_ids[0]} (from {len(top_gcm_ids)} candidates)\")\n",
    "    output_ids = get_srf_outs(themes.gcm_lut, [top_gcm_ids[0]])\n",
    "    if verbose: print(f\"Mapping {len(output_ids)} filtered SRF Outputs...\")\n",
    "    outputs_res = map_themes(system_blocks, fmt_srf_outs(themes.srf_outs, output_ids), prompts.srf_outputs, **kwargs)\n",
    "    return AttrDict(enablers=enablers_res, ccp=ccp_res, gcm=gcm_res, outputs=outputs_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b215d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping SRF Enablers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Cross-cutting Priorities...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping GCM Objectives...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top GCM: 7 (from 2 candidates)\n",
      "Mapping 26 filtered SRF Outputs...\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "res = map_all(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26709af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'theme_id': 'Cross-cutting 3',\n",
       "  'theme_title': 'Funding',\n",
       "  'centrality_score': 0.82,\n",
       "  'reasoning': \"Funding is a PRIMARY FOCUS. The evaluation identifies inadequate resource allocation as a central finding, appearing prominently in the Executive Summary: 'Resources allocated to central AAP functions remain inadequate.' Funding is addressed extensively across multiple sections: the AAP Coordination Unit lacks core funding and relies on 'earmarked funds'; country-level AAP is 'project-specific' creating fragmentation; there is 'no strategic approach to AAP funding' (Conclusions). Recommendations 2, 4, and 5 all directly address funding strategy and mechanisms. However, broader financing innovation, multi-year programming, and flexible fundingâ€”elements of the enabler descriptionâ€”are not explored, limiting it from 0.9.\",\n",
       "  'confidence': 'high'},\n",
       " {'theme_id': 'Cross-cutting 2',\n",
       "  'theme_title': 'Partnership',\n",
       "  'centrality_score': 0.68,\n",
       "  'reasoning': \"Partnership is a major component of the AAP Framework itself. The evaluation emphasizes 'inter-agency AAP coordination spaces' and 'collective accountability' as critical themes (Conclusions section). Recommendation 9 explicitly addresses 'collaboration and engagement on collective accountability' and participation in IASC structures. The case studies reference partnerships with government and civil society. However, partnership development for broader IOM programming, equitable partnerships with national actors, and whole-of-society solutions receive limited analysis. Partnerships are discussed primarily within the narrow context of AAP coordination rather than as a strategic organizational capability.\",\n",
       "  'confidence': 'high'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "sort_by_centrality(res.enablers)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208abdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'theme_id': 'Cross-cutting 1',\n",
       "  'theme_title': 'Integrity, Transparency and Accountability',\n",
       "  'centrality_score': 0.95,\n",
       "  'reasoning': \"This is a THEMATIC EVALUATION of AAP, which directly operationalizes accountability to affected populations. The entire evaluation assesses IOM's commitment to 'active commitment to use power responsibly by taking account of, giving account to, and being held to account by the people' (Executive Summary). Accountability appears in evaluation objectives, findings on 'collective accountability' (Conclusions), CFM mechanisms (Recommendation 8), and visibility/transparency (Recommendation 6). The evaluation systematically assesses accountability structures, transparency of feedback mechanisms, and institutional commitment to these principles across multiple sections and recommendations.\",\n",
       "  'confidence': 'high'},\n",
       " {'theme_id': 'Cross-cutting 3',\n",
       "  'theme_title': 'Protection-centred',\n",
       "  'centrality_score': 0.72,\n",
       "  'reasoning': \"Protection is a MAJOR COMPONENT of this AAP-focused evaluation. Findings reference 'protection risks and needs of vulnerable populations' (Conclusions); the AAP Framework itself centers on rights-based approaches and placing affected populations' well-being in decision-making, aligning with Protection-centred priorities. CFM mechanisms (Recommendation 8) and participation structures (throughout) are protection-related accountability tools. PSEAH is mentioned in background documents (IN/234). However, dedicated assessment of child safeguarding, PSEAH mechanisms, or specific protection outcomes is limited. Protection underpins AAP's logic but is not independently evaluated.\",\n",
       "  'confidence': 'medium'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "sort_by_centrality(res.ccp)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5995cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '23']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_top_ids(res.gcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'theme_id': '3d31',\n",
       "  'theme_title': 'Government and civil society stakeholders have improved knowledge, skills and resources to protect the rights of vulnerable migrants, including children and victims of trafficking, and are equipped to apply a survivor-centered, gender-sensitive, human-rights based approach.',\n",
       "  'centrality_score': 0.75,\n",
       "  'reasoning': \"Directly relevant to AAP's human rights and vulnerable group protection focus. Report emphasizes AAP's grounding in human rights-based approaches (Conclusions, page 34: 'The desk review and consultations held confirmed that the IOM AAP approach considers the cross-cutting issues of human rights, gender equality and disability'). Findings address capacity gaps (Recommendations 4, 7 on training/support). However, evaluation does not assess actual vulnerable migrant protection outcomes or survivor-centered service deliveryâ€”focuses on organizational support capacity.\",\n",
       "  'confidence': 'high'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "sort_by_centrality(res.outputs)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bc583",
   "metadata": {},
   "source": [
    "Can you provide a title and a short description for this module?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Based on the code, here's a title and description:\n",
    "\n",
    "**Title:** Theme Mapper\n",
    "\n",
    "**Description:** Maps evaluation reports to IOM's Strategic Results Framework themes using LLM-based scoring. The module analyzes reports against four theme hierarchies (SRF Enablers, Cross-cutting Priorities, GCM Objectives, and SRF Outputs) using prompt caching for efficiency. Returns structured centrality scores with reasoning and confidence levels for each theme."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
