{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc76840",
   "metadata": {},
   "source": [
    "# IOMEval\n",
    "> AI-powered analysis and mapping of IOM evaluation reports to strategic frameworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d187f1",
   "metadata": {},
   "source": [
    "[![CI](https://github.com/franckalbinet/iomeval/actions/workflows/test.yaml/badge.svg)](https://github.com/franckalbinet/iomeval/actions/workflows/test.yaml)\n",
    "[![PyPI](https://img.shields.io/pypi/v/iomeval)](https://pypi.org/project/iomeval/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441fdd8",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```sh\n",
    "pip install iomeval\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f48f0",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "iomeval uses Claude for intelligent extraction and mapping. Set your Anthropic API key:\n",
    "\n",
    "```sh\n",
    "export ANTHROPIC_API_KEY='your-key-here'\n",
    "```\n",
    "\n",
    "add mistral also ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bff03",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "- **Automated PDF Processing**: Download and OCR evaluation reports with proper heading hierarchy\n",
    "- **Intelligent Section Extraction**: LLM-powered extraction of executive summaries, findings, conclusions, and recommendations\n",
    "- **Strategic Framework Mapping**: Map report content to IOM's SRF Enablers, Cross-Cutting Priorities, GCM Objectives, and SRF Outputs\n",
    "- **Checkpoint/Resume**: Built-in state persistence - interrupt and resume long-running pipelines\n",
    "- **Granular Control**: Use the full pipeline or individual components as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acdbb3",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "Process an evaluation report end-to-end:\n",
    "\n",
    "```python\n",
    "from iomeval.pipeline import Report, run_pipeline\n",
    "\n",
    "report = Report(id=\"IOM-2024-001\", pdf_url=\"evaluation_report.pdf\")\n",
    "run_pipeline(report)\n",
    "```\n",
    "\n",
    "The rich display shows processing status across all pipeline stages - from OCR through framework mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662197d",
   "metadata": {},
   "source": [
    "## Understanding Evaluation Mapping in the UN Context\n",
    "\n",
    "UN agencies conduct hundreds of evaluations annually. Each report contains valuable insights about what works (and what doesn't) in international development and humanitarian response. However, these insights are often:\n",
    "\n",
    "- Buried in lengthy PDF documents\n",
    "- Difficult to compare across projects\n",
    "- Hard to connect to strategic frameworks and goals\n",
    "\n",
    "iomeval addresses this by automatically extracting key sections and mapping findings to IOM's strategic frameworks, enabling:\n",
    "\n",
    "- **Portfolio Analysis**: Understand patterns across multiple evaluations\n",
    "- **Strategic Alignment**: See how project outcomes connect to organizational priorities\n",
    "- **Knowledge Management**: Make evaluation insights searchable and comparable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c424614",
   "metadata": {},
   "source": [
    "## Detailed Workflow\n",
    "\n",
    "For more control, use individual pipeline stages:\n",
    "\n",
    "### 1. Load evaluation metadata\n",
    "\n",
    "```python\n",
    "from iomeval.readers import read_iom\n",
    "\n",
    "evals = read_iom()  # Returns DataFrame of all IOM evaluations\n",
    "evals.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ab77",
   "metadata": {},
   "source": [
    "### 2. Download and OCR a report\n",
    "\n",
    "```python\n",
    "from iomeval.downloaders import download_pdf\n",
    "from iomeval.core import pdf_to_md\n",
    "\n",
    "# Download PDF\n",
    "pdf_path = download_pdf(report.pdf_url, dest_folder=\"pdfs\")\n",
    "\n",
    "# Convert to markdown with heading hierarchy\n",
    "report.md = pdf_to_md(pdf_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ead15",
   "metadata": {},
   "source": [
    "### 3. Extract key sections\n",
    "\n",
    "```python\n",
    "from iomeval.extract import extract_exec_summary, extract_findings, extract_conclusions, extract_recommendations\n",
    "\n",
    "report.exec_summary = extract_exec_summary(report.md)\n",
    "report.findings = extract_findings(report.md)\n",
    "report.conclusions = extract_conclusions(report.md)\n",
    "report.recommendations = extract_recommendations(report.md)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e74e0",
   "metadata": {},
   "source": [
    "### 4. Map to strategic frameworks\n",
    "\n",
    "```python\n",
    "from iomeval.mapper import map_srf_enablers, map_srf_crosscutting, map_gcm, map_srf_outputs\n",
    "\n",
    "# Each mapper returns structured results with centrality scores\n",
    "report.srf_enablers = map_srf_enablers(report.conclusions)\n",
    "report.srf_crosscutting = map_srf_crosscutting(report.conclusions)\n",
    "report.gcm = map_gcm(report.conclusions)\n",
    "report.srf_outputs = map_srf_outputs(report.conclusions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5bd314",
   "metadata": {},
   "source": [
    "### 5. Save/restore checkpoints\n",
    "\n",
    "```python\n",
    "# Save progress\n",
    "report.save(\"checkpoint.json\")\n",
    "\n",
    "# Resume later\n",
    "report = Report.load(\"checkpoint.json\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a438f4d",
   "metadata": {},
   "source": [
    "## Development\n",
    "\n",
    "iomeval is built with [nbdev](https://nbdev.fast.ai/), which means the entire library is developed in Jupyter notebooks. The notebooks serve as both documentation and source code.\n",
    "\n",
    "### Setup for development\n",
    "\n",
    "```sh\n",
    "git clone https://github.com/franckalbinet/iomeval.git\n",
    "cd iomeval\n",
    "pip install -e '.[dev]'\n",
    "```\n",
    "\n",
    "### Key nbdev commands\n",
    "\n",
    "```sh\n",
    "nbdev_test          # Run tests in notebooks\n",
    "nbdev_export        # Export notebooks to Python modules\n",
    "nbdev_preview       # Preview documentation site\n",
    "nbdev_prepare       # Export, test, and clean notebooks (run before committing)\n",
    "```\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. Make changes in the `.ipynb` notebook files\n",
    "2. Run `nbdev_prepare` to export code and run tests\n",
    "3. Commit both notebooks and exported Python files\n",
    "4. Documentation is automatically generated from the notebooks\n",
    "\n",
    "Learn more about nbdev's literate programming approach in the [nbdev documentation](https://nbdev.fast.ai/).\n",
    "\n",
    "### Contributing\n",
    "\n",
    "Contributions are welcome! Please:\n",
    "- Follow the existing notebook structure\n",
    "- Add tests using nbdev's `#| test` cells\n",
    "- Run `nbdev_prepare` before submitting PRs"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
